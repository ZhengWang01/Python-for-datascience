{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/Jacqueline/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY\n",
    "\n",
    "nltk.download(\"twitter_samples\")\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative_tweets.json', 'positive_tweets.json', 'tweets.20150430-223406.json']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "twitter_samples.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "number_of_positive_tweets = None\n",
    "### BEGIN SOLUTION\n",
    "positive_tweets = twitter_samples.tokenized(\"positive_tweets.json\")\n",
    "number_of_positive_tweets = len(positive_tweets)\n",
    "number_of_positive_tweets\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_negative_tweets = None\n",
    "### BEGIN SOLUTION\n",
    "negative_tweets = twitter_samples.tokenized(\"negative_tweets.json\")\n",
    "number_of_negative_tweets = len(negative_tweets)\n",
    "number_of_negative_tweets\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY\n",
    "\n",
    "assert number_of_positive_tweets == 5000, \"Make sure you are counting the number of tweets, not the number of words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_words = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_bag_of_words_features_filtered(words):\n",
    "    \"\"\"Build a bag of words model\"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    word_dic = {}\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word not in useless_words:\n",
    "            word_dic[word] = 1\n",
    "            \n",
    "    return word_dic\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert len(build_bag_of_words_features_filtered([\"what\", \"the\", \"?\", \",\"]))==0, \"Make sure we are filtering out both stopwords and punctuation\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for dataset in [\"positive_tweets.json\", \"negative_tweets.json\"]:\n",
    "    for tweet in twitter_samples.tokenized(dataset):\n",
    "        words.extend(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78368"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words = []\n",
    "### BEGIN SOLUTION\n",
    "for word in words:\n",
    "        word = word.lower()\n",
    "        if word not in useless_words:\n",
    "            filtered_words.append(word)\n",
    "### END SOLUTION\n",
    "len(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(':(', 4586),\n",
       " (':)', 3693),\n",
       " (':-)', 701),\n",
       " (':d', 658),\n",
       " ('...', 622),\n",
       " (\"i'm\", 526),\n",
       " (':-(', 501),\n",
       " ('thanks', 469),\n",
       " ('follow', 446),\n",
       " ('u', 438)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "most_common_words = None\n",
    "### BEGIN SOLUTION\n",
    "most_common_words = counter.most_common()[:10]\n",
    "most_common_words\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert most_common_words[0][0] == \":(\", \"The most common word should be :(\"\n",
    "assert len(most_common_words) == 10, \"Make sure you are only getting the first 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'hopeless': 1, 'tmr': 1, ':(': 1}, 'neg'),\n",
       " ({'everything': 1,\n",
       "   'kids': 1,\n",
       "   'section': 1,\n",
       "   'ikea': 1,\n",
       "   'cute': 1,\n",
       "   'shame': 1,\n",
       "   \"i'm\": 1,\n",
       "   'nearly': 1,\n",
       "   '19': 1,\n",
       "   '2': 1,\n",
       "   'months': 1,\n",
       "   ':(': 1},\n",
       "  'neg'),\n",
       " ({'@hegelbon': 1, 'heart': 1, 'sliding': 1, 'waste': 1, 'basket': 1, ':(': 1},\n",
       "  'neg'),\n",
       " ({'“': 1,\n",
       "   '@ketchburning': 1,\n",
       "   'hate': 1,\n",
       "   'japanese': 1,\n",
       "   'call': 1,\n",
       "   'bani': 1,\n",
       "   ':(': 1,\n",
       "   '”': 1},\n",
       "  'neg')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_features = None\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "### END SOLUTION\n",
    "negative_features = []\n",
    "\n",
    "for tweet in negative_tweets:\n",
    "    toop = build_bag_of_words_features_filtered(tweet), 'neg'\n",
    "    negative_features.append(toop)\n",
    "negative_features[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'#followfriday': 1,\n",
       "   '@france_inte': 1,\n",
       "   '@pkuchly57': 1,\n",
       "   '@milipol_paris': 1,\n",
       "   'top': 1,\n",
       "   'engaged': 1,\n",
       "   'members': 1,\n",
       "   'community': 1,\n",
       "   'week': 1,\n",
       "   ':)': 1},\n",
       "  'pos'),\n",
       " ({'@lamb2ja': 1,\n",
       "   'hey': 1,\n",
       "   'james': 1,\n",
       "   'odd': 1,\n",
       "   ':/': 1,\n",
       "   'please': 1,\n",
       "   'call': 1,\n",
       "   'contact': 1,\n",
       "   'centre': 1,\n",
       "   '02392441234': 1,\n",
       "   'able': 1,\n",
       "   'assist': 1,\n",
       "   ':)': 1,\n",
       "   'many': 1,\n",
       "   'thanks': 1},\n",
       "  'pos'),\n",
       " ({'@despiteofficial': 1,\n",
       "   'listen': 1,\n",
       "   'last': 1,\n",
       "   'night': 1,\n",
       "   ':)': 1,\n",
       "   'bleed': 1,\n",
       "   'amazing': 1,\n",
       "   'track': 1,\n",
       "   'scotland': 1},\n",
       "  'pos'),\n",
       " ({'@97sides': 1, 'congrats': 1, ':)': 1}, 'pos')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "positive_features = None\n",
    "### BEGIN SOLUTION\n",
    "positive_features = []\n",
    "\n",
    "for tweet in positive_tweets:\n",
    "    toop = build_bag_of_words_features_filtered(tweet), 'pos'\n",
    "    positive_features.append(toop)\n",
    "positive_features[:4]\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert positive_features[0][1] == \"pos\", \"Make sure the feature is a list of tuples whose second element is pos or neg\"\n",
    "assert positive_features[0][0][\"engaged\"] == 1, \"Make sure that the first element of each tuple is a dictionary of words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(positive_features) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier.train(positive_features[:split]+negative_features[:split])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.4"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_accuracy = None\n",
    "### BEGIN SOLUTION\n",
    "training_accuracy = nltk.classify.util.accuracy(classifier, positive_features[split:]+negative_features[split:])*100\n",
    "### END SOLUTION\n",
    "training_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                      :( = 1                 neg : pos    =   2362.3 : 1.0\n",
      "                      :) = 1                 pos : neg    =   1139.0 : 1.0\n",
      "                     x15 = 1                 neg : pos    =     23.7 : 1.0\n",
      "                     sad = 1                 neg : pos    =     21.4 : 1.0\n",
      "                    sick = 1                 neg : pos    =     21.0 : 1.0\n",
      "                    glad = 1                 pos : neg    =     16.6 : 1.0\n",
      "               community = 1                 pos : neg    =     16.3 : 1.0\n",
      "                 arrived = 1                 pos : neg    =     15.9 : 1.0\n",
      "                     ugh = 1                 neg : pos    =     15.0 : 1.0\n",
      "                   loves = 1                 pos : neg    =     14.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
